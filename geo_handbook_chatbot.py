# -*- coding: utf-8 -*-
"""Copy of Llama2llamaindexDemo.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1874AyQPVNH5LqHAJIbgCpEKBArlR0ED9
"""

# pip install pypdf
# pip install python-dotenv

# pip install -q transformers einops accelerate langchain bitsandbytes

# pip install sentence_transformers

# pip install llama-index

import logging
import os
import sys
import torch

# Configure environment variables
# Setting the maximum number of threads that NumExpr can use to 56 to potentially improve performance
os.environ['NUMEXPR_MAX_THREADS'] = '8'

# Set up logging
# Configuring the basic settings for logging, setting the logging level to INFO, 
# which means that INFO and higher level messages will be logged
logging.basicConfig(stream=sys.stdout, level=logging.INFO)

# Adding a stream handler that outputs log messages to sys.stdout
logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))

# Import necessary classes and functions
# Importing classes and functions needed to initialize the components in the next sections
from llama_index import VectorStoreIndex, SimpleDirectoryReader, ServiceContext, LangchainEmbedding
from llama_index.llms import HuggingFaceLLM
from llama_index.prompts.prompts import SimpleInputPrompt
from langchain.embeddings.huggingface import HuggingFaceEmbeddings

# Initialize necessary components
# Defining a prompt that will guide the assistant's behavior while answering questions
system_prompt = "You are a Q&A assistant for graduate students at Oregon State University in the Geography Department. Your goal is to answer questions as accurately as possible based on the instructions and context provided for graduate students. You are not able to answer questions for undergraduates or anything outside the context of the document provided."

# Creating a wrapper for the query using a simple input prompt
query_wrapper_prompt = SimpleInputPrompt("{query_str}")

# Loading documents from the "data/" directory using SimpleDirectoryReader
documents = SimpleDirectoryReader("data/geo/").load_data()

# Initializing the embedding model with a pretrained HuggingFace model
embed_model = LangchainEmbedding(HuggingFaceEmbeddings(model_name="sentence-transformers/all-mpnet-base-v2"))

# Logging in to the Hugging Face CLI - this is a command line instruction and should be run in a CLI, not in a Python script
# huggingface-cli login

# Configure LLM
# Initializing a HuggingFace LLM (Language model) with various settings such as context window size, token limits, and others
llm = HuggingFaceLLM(
    context_window=4096,
    max_new_tokens=256,
    generate_kwargs={
        "do_sample": True,
        "temperature": 1.0,
        "top_p": 0.9,
    },
    system_prompt=system_prompt,
    query_wrapper_prompt=query_wrapper_prompt,
    tokenizer_name="meta-llama/Llama-2-7b-chat-hf",
    model_name="meta-llama/Llama-2-7b-chat-hf",
    device_map="auto",
)

# Configure service context and index
# Creating a service context with default settings, including the chunk size and the LLM and embedding model initialized earlier
service_context = ServiceContext.from_defaults(
    chunk_size=1024,
    llm=llm,
    embed_model=embed_model
)

# Creating an index from the loaded documents with the service context
index = VectorStoreIndex.from_documents(documents, service_context=service_context)

# Creating a query engine from the index to facilitate querying
query_engine = index.as_query_engine()

# Define a function to ask questions
def ask_question(question_str):
    return query_engine.query(question_str)


ask_question("Who is the Associate Dean for Faculty Development and Graduate Academic Programs?")

response = ask_question("Who is the Associate Dean for Faculty Development and Graduate Academic Programs?")
print(response)

# response = query_engine.query("What new vehicles did Tata launch in 2022?")

q1 = query_engine.query("Who is the Associate Dean for Faculty Development and Graduate Academic Programs?")
print(q1)

q2 = query_engine.query("Who issues keys for offices and facilities?")
print(q2)

q3 = query_engine.query("What is the required grade point average?")
print(q3)

q4 = query_engine.query("Can you provide year 1 and year 2 tasks for completing a geography MS project?")
print(q4)

q5 = query_engine.query("Can you provide a summary of the written questions section of the Geography PhD preliminary exam?")
print(q5)

q6 = ask_question("I am a PhD student in the geography department and need to know what I need to do to finish my phd in my 4th year?")
print(q6)

q7 = ask_question("Where can I find out about funding for an upcoming conference?")
print(q7)

q8 = ask_question("I am a masters student in the geography department and I'm thinking about doing a PhD. Can I change from a masters to a PhD and if so what do I need to do?")
print(q8)

q9 = ask_question("What are the requirements for an undergraduate degree in geography (not a graduate degree)?")
print(q9)

q10 = ask_question("what are the required courses I need to take as a PhD student in Geography at Oregon State University?")
print(q10)
